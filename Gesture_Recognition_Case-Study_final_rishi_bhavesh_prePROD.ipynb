{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "## Deep Learning  Assignment - Gesture Recognition\n",
    "\n",
    "### Problem Statement\n",
    "Imagine you are working as a data scientist at a home electronics company which manufactures state of the art smart televisions. You want to develop a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote.\n",
    "\n",
    "The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command:\n",
    " \n",
    "| Gesture | Corresponding Action |\n",
    "| --- | --- | \n",
    "| Thumbs Up | Increase the volume. |\n",
    "| Thumbs Down | Decrease the volume. |\n",
    "| Left Swipe | 'Jump' backwards 10 seconds. |\n",
    "| Right Swipe | 'Jump' forward 10 seconds. |\n",
    "| Stop | Pause the movie. |\n",
    "\n",
    "Each video is a sequence of 30 frames (or images).\n",
    "\n",
    "### Objectives:\n",
    "1. **Generator**:  The generator should be able to take a batch of videos as input without any error. Steps like cropping, resizing and normalization should be performed successfully.\n",
    "\n",
    "2. **Model**: Develop a model that is able to train without any errors which will be judged on the total number of parameters (as the inference(prediction) time should be less) and the accuracy achieved. As suggested by Snehansu, start training on a small amount of data and then proceed further.\n",
    "\n",
    "3. **Write up**: This should contain the detailed procedure followed in choosing the final model. The write up should start with the reason for choosing the base model, then highlight the reasons and metrics taken into consideration to modify and experiment to arrive at the final model. Checking the GPU configuration\n",
    "\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import abc\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)\n",
    "#tf.random.set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing some other libraries which will be needed for model building.\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder='Project_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the training/validation accuracies/losses.\n",
    "\n",
    "def plot(history):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(history.history['loss'])   \n",
    "    axes[0].plot(history.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(history.history['categorical_accuracy'])   \n",
    "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=20,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=15,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we see from the above experiments **\"image resolution\"** and **number of frames** in sequence have more impact on training time than **batch_size**\n",
    "- We can consider the Batch Size around 15-40\n",
    "- We will change the resoulution 160*160, 120*120 according the model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "### Base Model - Batch Size = 40 and No. of Epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConv3D1(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=20,batch_size=40,num_epochs=15)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "conv_3d1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "history_model1 = conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Image resolution, number of frames to use and batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We had hit the limit on memory resources with image resolution of 160x160 with 30 frames and batch_size of 40...we get the below error\n",
    "\n",
    "ResourceExhaustedError: OOM when allocating tensor with shape[40,16,30,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Memory util is {} Gigs\". format(getsizeof(np.zeros((40,16,30,160,160)))/(1024*1024*1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So lets trade-off between these parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Below are the experiments to see how training time is affected by image resolution, number of images in sequence and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=15,batch_size=30,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Please enter the commit message for your changes. Lines starting## Experimenting with Image resolution, number of frames to use and batch_size\n",
    "\n",
    "#conv_3d1.train_model(conv_3d1_model)\n",
    "\n",
    "### We had hit the limit on memory resources with image resolution of 160x160 with 30 frames and batch_size of 40...we get the below error\n",
    "\n",
    "ResourceExhaustedError: OOM when allocating tensor with shape[40,16,30,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
    "\n",
    "print(\"Memory util is {} Gigs\". format(getsizeof(np.zeros((40,16,30,160,160)))/(1024*1024*1024)))\n",
    "\n",
    "##### So lets trade-off between these parameters\n",
    "\n",
    "##### Below are the experiments to see how training time is affected by image resolution, number of images in sequence and batch size\n",
    "\n",
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=15,batch_size=30,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)class ModelBuilder(metaclass= abc.ABCMeta):\n",
    "    # initialisng the path where project data resides\n",
    "    def initialize_path(self,project_folder):\n",
    "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
    "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
    "        self.train_path = project_folder + '/' + 'train'\n",
    "        self.val_path =  project_folder + '/' + 'val'\n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "    # initialising the image properties    \n",
    "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
    "        self.image_height=image_height\n",
    "        self.image_width=image_width\n",
    "        self.channels=3\n",
    "        self.num_classes=5\n",
    "        self.total_frames=30\n",
    "    # initialising the batch size, frames to sample and the no. of epochs\n",
    "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=20,num_epochs=20):\n",
    "        self.frames_to_sample=frames_to_sample\n",
    "        self.batch_size=batch_size\n",
    "        self.num_epochs=num_epochs\n",
    "        \n",
    "    # MOST IMPORTANT PART HERE - The generator function        \n",
    "    def generator(self,source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
    "        batch_size=self.batch_size\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(t)//batch_size\n",
    "        \n",
    "            for batch in range(num_batches): \n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
    "                yield batch_data, batch_labels \n",
    "\n",
    "            remaining_seq=len(t)%batch_size\n",
    "        \n",
    "            if (remaining_seq != 0):\n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
    "                yield batch_data, batch_labels \n",
    "    \n",
    "    \n",
    "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
    "    \n",
    "        seq_len = remaining_seq if remaining_seq else batch_size\n",
    "    \n",
    "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
    "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
    "    \n",
    "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
    "\n",
    "        \n",
    "        for folder in range(seq_len): \n",
    "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
    "            for idx,item in enumerate(img_idx):\n",
    "                #performing image reading and resizing\n",
    "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                image_resized=imresize(image,(self.image_height,self.image_width,3))\n",
    "            \n",
    "                #normalizing the images\n",
    "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "            \n",
    "                if (augment):\n",
    "                    shifted = cv2.warpAffine(image, \n",
    "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
    "                                            (image.shape[1], image.shape[0]))\n",
    "                    \n",
    "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
    "                    # cropping the images to have the targeted gestures and remove the noise from the images.\n",
    "                    cropped=shifted[x0:x1,y0:y1,:]\n",
    "                    \n",
    "                    image_resized=imresize(cropped,(self.image_height,self.image_width,3))\n",
    "                    \n",
    "                    #shifted = cv2.warpAffine(image_resized, \n",
    "                    #                        np.float32([[1, 0, np.random.randint(-3,3)],[0, 1, np.random.randint(-3,3)]]), \n",
    "                    #                        (image_resized.shape[1], image_resized.shape[0]))\n",
    "            \n",
    "                    batch_data_aug[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                    batch_data_aug[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                    batch_data_aug[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "                \n",
    "            \n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "    \n",
    "        if (augment):\n",
    "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
    "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
    "\n",
    "        \n",
    "        return(batch_data,batch_labels)\n",
    "    \n",
    "    \n",
    "    def train_model(self, model, augment_data=False):\n",
    "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc)\n",
    "\n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "        \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
    "        \n",
    "        earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
    "        callbacks_list = [checkpoint, LR, earlystop]\n",
    "\n",
    "        if (self.num_train_sequences%self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences%self.batch_size) == 0:\n",
    "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
    "    \n",
    "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
    "                            callbacks=callbacks_list, validation_data=val_generator, \n",
    "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "        return history\n",
    "\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def define_model(self)##### Model is clearly overfitting. :(\n",
    "\n",
    "## Model 2  \n",
    "### Adding dropout layers - Batch Size = 20 and No. of Epochs = 25\n",
    "\n",
    "conv_3d2=ModelConv3D1()\n",
    "conv_3d2.initialize_path(project_folder)\n",
    "conv_3d2.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d2.initialize_hyperparams(frames_to_sample=20,batch_size=20,num_epochs=25)\n",
    "conv_3d2_model=conv_3d2.define_model(dense_neurons=256,dropout=0.5)\n",
    "conv_3d2_model.summary()\n",
    "\n",
    "print(\"Total Params:\", conv_3d2_model.count_params())\n",
    "history_model2=conv_3d2.train_model(conv_3d2_model,augment_data=True)\n",
    "\n",
    "plot(history_model2)\n",
    "\n",
    "##### We can see  val_loss did not improve from 1.24219 so earlystopping stops the epoch automatically!! \n",
    "- Last Epoch stop on 15/25!! good job earlystopping ;)\n",
    "- Best weights save automatically. The validation accuracy of 52% and training accuracy of 65%. Next we will try to reduce the filter size and image resolution and see if get better results. Moreover since we see minor oscillations  in loss, let's try lowering the learning rate to 0.0002\n",
    "\n",
    "## Model 3 \n",
    "### Reduce filter size to (2,2,2) and image res to 120 x  120, - Batch Size = 30 and No. of Epochs = 25\n",
    "\n",
    "class ModelConv3D3(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "        \n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model\n",
    "\n",
    "conv_3d3=ModelConv3D3()\n",
    "conv_3d3.initialize_path(project_folder)\n",
    "conv_3d3.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d3.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=25)\n",
    "conv_3d3_model=conv_3d3.define_model(filtersize=(2,2,2),dense_neurons=256,dropout=0.5)\n",
    "conv_3d3_model.summary()\n",
    "\n",
    "print(\"Total Params:\", conv_3d3_model.count_params())\n",
    "history_model3=conv_3d3.train_model(conv_3d3_model,augment_data=True)\n",
    "\n",
    "plot(history_model3):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
